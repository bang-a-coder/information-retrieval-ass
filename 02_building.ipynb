{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Building a Simple Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will build a simple search index, which we will use later for Boolean retrieval. The assignment tasks are again at the bottom of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summaries_file = 'data/emotion_Summaries.pkl.bz2'\n",
    "Abstracts_file = 'data/emotion_Abstracts.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2\n",
    "from collections import namedtuple\n",
    "\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )\n",
    "    \n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what the data looks like for an example of a paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper(title='Electrophysiological correlates of interference control in the modified emotional Stroop task with emotional stimuli differing in valence, arousal, and subjective significance.', authors=['Imbir KK', 'Pastwa M', 'Duda-Goławska J', 'Sobieszek A', 'Jankowska M', 'Modzelewska A', 'Wielgopolan A', 'Żygierewicz J'], year=2021, doi='10.1371/journal.pone.0258177')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summaries[34648542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The role of emotional factors in maintaining cognitive control is one of the most intriguing issues in understanding emotion-cognition interactions. In the current experiment, we assessed the role of emotional factors (valence, arousal, and subjective significance) in perceptual and conceptual inhibition processes. We operationalised both processes with the classical cognitive paradigms, i.e., the flanker task and the emotional Stroop task merged into a single experimental procedure. The procedure was based on the presentation of emotional words displayed in four different font colours flanked by the same emotional word printed with the same or different font colour. We expected to find distinct effects of both types of interference: earlier for perceptual and later for emotional interference. We also predicted an increased arousal level to disturb inhibitory control effectiveness, while increasing the subjective significance level should improve this process. As we used orthogonal manipulations of emotional factors, our study allowed us for the first time to assess interactions within emotional factors and between types of interference. We found on the behavioural level the main effects of flanker congruency as well as effects of emotionality. On the electrophysiological level, we found effects for EPN, P2, and N450 components of ERPs. The exploratory analysis revealed that effects due to perceptual interference appeared earlier than the effects of emotional interference, but they lasted for an extended period of processing, causing perceptual and emotional interference to partially overlap. Finally, in terms of emotional interference, we showed the effect of subjective significance: the reduction of interference cost in N450 for highly subjective significant stimuli. This study is the first one allowing for the investigation of two different types of interference in a single experiment, and provides insight into the role of emotion in cognitive control.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abstracts[34648542]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define some utility functions that allow us to tokenize a string into terms, perform linguistic preprocessing on a list of terms, as well as a function to display information about a paper in a nice way. Note that these tokenization and preprocessing functions are rather naive. We will improve them in a later assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorem', 'ipsum', 'dolor', 'sit', 'amet']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function that tokenizes a string in a rather naive way. Can be extended later.\n",
    "    \"\"\"\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    \"\"\"\n",
    "    Perform linguistic preprocessing on a list of tokens. Can be extended later.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result\n",
    "\n",
    "print(preprocess(tokenize(\"Lorem ipsum dolor sit AMET\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1371/journal.pone.0258177>Electrophysiological correlates of interference control in the modified emotional Stroop task with emotional stimuli differing in valence, arousal, and subjective significance.</a></strong><br>2021. Imbir KK, Pastwa M, Duda-Goławska J, Sobieszek A, Jankowska M, Modzelewska A, Wielgopolan A, Żygierewicz J<br>[ID: 34648542]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1371/journal.pone.0258177>Electrophysiological correlates of interference control in the modified emotional Stroop task with emotional stimuli differing in valence, arousal, and subjective significance.</a></strong><br>2021. Imbir KK, Pastwa M, Duda-Goławska J, Sobieszek A, Jankowska M, Modzelewska A, Wielgopolan A, Żygierewicz J<br><small><strong>Abstract:</strong> <em>The role of emotional factors in maintaining cognitive control is one of the most intriguing issues in understanding emotion-cognition interactions. In the current experiment, we assessed the role of emotional factors (valence, arousal, and subjective significance) in perceptual and conceptual inhibition processes. We operationalised both processes with the classical cognitive paradigms, i.e., the flanker task and the emotional Stroop task merged into a single experimental procedure. The procedure was based on the presentation of emotional words displayed in four different font colours flanked by the same emotional word printed with the same or different font colour. We expected to find distinct effects of both types of interference: earlier for perceptual and later for emotional interference. We also predicted an increased arousal level to disturb inhibitory control effectiveness, while increasing the subjective significance level should improve this process. As we used orthogonal manipulations of emotional factors, our study allowed us for the first time to assess interactions within emotional factors and between types of interference. We found on the behavioural level the main effects of flanker congruency as well as effects of emotionality. On the electrophysiological level, we found effects for EPN, P2, and N450 components of ERPs. The exploratory analysis revealed that effects due to perceptual interference appeared earlier than the effects of emotional interference, but they lasted for an extended period of processing, causing perceptual and emotional interference to partially overlap. Finally, in terms of emotional interference, we showed the effect of subjective significance: the reduction of interference cost in N450 for highly subjective significant stimuli. This study is the first one allowing for the investigation of two different types of interference in a single experiment, and provides insight into the role of emotion in cognitive control.</em></small><br>[ID: 34648542]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import re\n",
    "\n",
    "def display_summary( id, show_abstract=False, show_id=True, extra_text='' ):\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long author lists, and adds a link to the paper's DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[id]\n",
    "    lines = []\n",
    "    title = s.title\n",
    "    if s.doi != '':\n",
    "        title = '<a href=http://dx.doi.org/{:s}>{:s}</a>'.format(s.doi, title)\n",
    "    title = '<strong>' + title + '</strong>'\n",
    "    lines.append(title)\n",
    "    authors = ', '.join( s.authors[:20] ) + ('' if len(s.authors) <= 20 else ', ...')\n",
    "    lines.append(str(s.year) + '. ' + authors)\n",
    "    if (show_abstract):\n",
    "        lines.append('<small><strong>Abstract:</strong> <em>{:s}</em></small>'.format(Abstracts[id]))\n",
    "    if (show_id):\n",
    "        lines.append('[ID: {:d}]'.format(id))\n",
    "    if (extra_text != ''):\n",
    "         lines.append(extra_text)\n",
    "    display( HTML('<br>'.join(lines)) )\n",
    "\n",
    "display_summary(34648542)\n",
    "display_summary(34648542, show_abstract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our first index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create an _inverted index_ based on the words in the titles and abstracts of the papers in our dataset. We will implement our inverted index as a Python dictionary with term strings as keys and posting lists (implemented as Python lists) as values. We include all the tokens we can find in the title and (if available) in the abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "inverted_index = defaultdict(list)\n",
    "\n",
    "# This can take a few seconds:\n",
    "for id in sorted(Summaries.keys()):\n",
    "    term_set = set(preprocess(tokenize(Summaries[id].title)))\n",
    "    if id in Abstracts:\n",
    "        term_set.update(preprocess(tokenize(Abstracts[id])))\n",
    "    for term in term_set:\n",
    "        inverted_index[term].append(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what's in the index for the example term 'amsterdam':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9756244, 16916567, 21859206, 25186285, 26784347, 29218587, 29406610, 33741990]\n"
     ]
    }
   ],
   "source": [
    "print(inverted_index['amsterdam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this inverted index to answer simple one-word queries, for example to show all papers that contain the word 'utrecht':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1111/1467-9450.00025>The CODE: a revised battery for coping and defense and its relations to subjective health.</a></strong><br>1997. Eriksen HR, Olff M, Ursin H<br><small><strong>Abstract:</strong> <em>A condensed test battery (the CODE) based on the Utrecht Coping List (UCL) and part of the Defense Mechanisms Inventory (DMI) has been developed to assess coping and defense in large population studies. It was tested for reliability and validity in students and back pain patients. Principal components factor analysis of the subscales of the UCL and DMI in the student sample revealed two coping clusters: \"Instrumental mastery-oriented coping\" and \"Emotion-focused coping\" and two defensive clusters: \"Cognitive defense\" and \"Defensive hostility\". \"Instrumental mastery-oriented coping\" was negatively related to subjective health complaints measured with Ursins Health Inventory (UHI). The back pain patients were clearly different from the students, using less coping and more defensive strategies. They had more subjective health complaints that showed negative correlations with \"Instrumental mastery-oriented coping\". The CODE is a comprehensive battery that may be valid for large population studies of psychological determinants of muscle pain and other subjective health problems.</em></small><br>[ID: 9309949]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1046/j.1365-2850.2003.00618.x>The mental health of women with suspected breast cancer: the relationship between social support, anxiety, coping and defence in maintaining mental health.</a></strong><br>2003. Drageset S, Lindstrøm TC<br><small><strong>Abstract:</strong> <em>Relationships between anxiety, social support, coping, and defence, in connection to mental health, were studied among patients with suspected breast cancer, awaiting diagnosis. Data were collected by questionnaires from 117 women, 25-76 years of age (mean: 53.6 years) who had undergone breast biopsy. Instruments used were: the Social Provisions Scale (SPS); the state scale of State-Trait Anxiety Scale (STAI); and CODE [based on the Utrecht Coping List (UCL) and Defence Mechanisms Inventory (DMI)]. The results showed that patients reported elevated levels of anxiety and high levels of social support. Yet, anxiety was strongest and negatively related to 'instrumental coping', followed by 'cognitive defence'. 'Defensive hostility' was unrelated to anxiety. Unexpectedly, 'emotion-focused coping' and social provisions were unrelated to anxiety. Social provisions were somewhat related to 'instrumental coping', but sparsely related to 'emotion-focused coping', unrelated to 'cognitive defence' and partly negatively related to 'defensive hostility'. Hence, social support and 'emotion-focused coping' did not in themselves repress anxiety. 'Instrumental coping' did, even in a situation where nothing could be done. Social support is suggested to be the product of an 'instrumental coping style', not necessarily contributing to it. Clinical consequences for professional information and support to patients with different coping styles are suggested.</em></small><br>[ID: 12887631]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1002/erv.2173>A psychometric evaluation of an English version of the Utrecht Coping List.</a></strong><br>2012. Turner H, Bryant-Waugh R, Peveler R, Bucks RS<br><small><strong>Abstract:</strong> <em>Although coping styles in individuals with eating disorders have received increased research interest in recent years, there remains a lack of brief, self-report measures that can reliably measure coping. This study developed an English version of the Utrecht Coping List (UCL) and evaluated its psychometric properties in a UK population.</em></small><br>[ID: 22419565]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1080/09602011.2019.1692670>The relationship between social cognition and participation in the long term after stroke.</a></strong><br>2021. Stiekema APM, Nijsse B, de Kort PLM, Spikman JM, Visser-Meily JMA, van Heugten CM<br><small><strong>Abstract:</strong> <em>Social cognitive impairments may play a role in participation restrictions after stroke. Understanding their relationship could inform treatment approaches to improve participation. We investigated the relationship between social cognition and participation in the long term after stroke. Of 395 patients participating in a large prospective cohort study, cross-sectional data were available at 3-4 years post-stroke of 118 patients on tests for emotion recognition, theory of mind, empathy, and behaviour regulation. Participation was assessed with the Utrecht Scale for Evaluation of Rehabilitation - Participation (USER-P). Bivariate and multivariate regression analysis were used to examine the relationship between social cognitive domains and participation. The majority suffered from minor stroke (83.1% scored NIHSS 0-4). Only behaviour regulation was related to participation restrictions in bivariate analysis, but social cognitive impairments did not predict participation restrictions in multivariate regression in this group. To conclude, in a sample of minor stroke patients with mild impairments in theory of mind, emotion recognition and behavioural control, there were no associations with restrictions in participation. Research should examine whether a relationship is present in patients with more severe stroke. In addition, measuring social aspects of participation is necessary to further unravel this relationship, to determine treatment targets for improving participation.</em></small><br>[ID: 31854264]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.3389/fpsyg.2021.735969>A Study on Chinese EFL Teachers' Work Engagement: The Predictability Power of Emotion Regulation and Teacher Resilience.</a></strong><br>2021. Xie F<br><small><strong>Abstract:</strong> <em>Employing a sequential mixed-methods design, the current study examined the role of Chinese EFL teachers' emotion regulation and resilience in predicting their work engagement. To this end, 314 Chinese EFL teachers with various academic degrees and teaching experiences were opted from different schools, institutes, and universities of China. To obtain the quantitative data, Utrecht Work Engagement Scale (UWES), Connor-Davidson Resilience Scale (CD-RISC), and Emotion Regulation Questionnaire (ERQ) were electronically distributed among participants. Performing correlational analyses, a strong association was found between teacher resilience and work engagement. The inspection of the correlations also revealed a moderate correlation between cognitive reappraisal and resilience as well as cognitive reappraisal and work engagement. To probe the predictability power of teacher resilience and emotion regulation (cognitive reappraisal), structural equation modeling (SEM) was performed. The results of the SEM analysis demonstrated that Chinese EFL teachers' work engagement was predicted significantly and favorably by their resilience. Using semi-structured interviews, some qualitative data were also collected to fully understand Chinese EFL teachers' perceptions of work engagement. The thematic analysis (TA) of Chinese EFL teachers' responses to interview questions resulted in two main themes and 14 sub-themes, revealing extrinsic and intrinsic factors contributing to teaching engagement. The findings of TA illuminated that both personal resources and job resources can predict teaching engagement. The pedagogical implications for administrators and teacher trainers are further discussed.</em></small><br>[ID: 34512487]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_word = 'utrecht'\n",
    "for i in inverted_index[query_word]:\n",
    "    display_summary(i, show_abstract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** Nikitas Filosofof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9309949, 12887631, 22419565, 31854264, 34512487] [9756244, 16916567, 21859206, 25186285, 26784347, 29218587, 29406610, 33741990]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9309949, 12887631, 22419565, 31854264, 34512487]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inverted_index['utrecht'],inverted_index['amsterdam'])\n",
    "\n",
    "min((inverted_index['utrecht'],inverted_index['amsterdam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Implement the function `and_merge` outlined below. This function takes two posting lists from the index that can be assumed to be sorted already, and it should return the result of the merging of the two lists with AND. The resulting list should therefore include all the elements that appear in both lists. As explained on the slides, this operation should take advantage of the input lists being sorted already, should not perform any additional sorting operation, and should go through each of the input lists just once. Then, test your function with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 16916569, 22419565]\n",
      "[2513080, 2597883, 7149759, 9458505, 15058096, 16001596, 18954194, 19161959, 23204355, 23266169, 25455331, 29278692, 30356814, 30482104, 30707087, 30957656, 31419610, 31507492, 32435316, 33836214, 33955347, 34058956]\n"
     ]
    }
   ],
   "source": [
    "def and_merge(sorted_list1, sorted_list2):\n",
    "    merged_list = []\n",
    "    # first we make copies of the lists, so we don't modify the existing lists in the index:\n",
    "    list1 = list(sorted_list1)\n",
    "    list2 = list(sorted_list2)\n",
    "\n",
    "    #iterators\n",
    "    it_1 = 0\n",
    "    it_2 = 0\n",
    "\n",
    "    while it_1 < len(list1) and it_2 < len(list2): #  checking if it exceeds the max len of any list, merge_list can have at most len(min(sorted_list1,sorted_list2)) elements\n",
    "        if list1[it_1] == list2[it_2]:\n",
    "            merged_list.append(list1[it_1])\n",
    "            it_1 += 1\n",
    "            it_2 += 1\n",
    "        elif list1[it_1] < list2[it_2]:\n",
    "            it_1 += 1\n",
    "        else:\n",
    "            it_2 += 1\n",
    "\n",
    "    return merged_list\n",
    "\n",
    "sampl1= [4,9309949, 12887631, 16916569, 22419565, 31854264, 34512487] \n",
    "sample2= [1,4,6,6,6,6,6,6,6,6,6,9756244, 16916567, 16916569, 21859206,22419565, 25186285, 26784347, 29218587, 29406610, 33741990]\n",
    "\n",
    "# testing:\n",
    "print(and_merge(sampl1,sample2))\n",
    "print(and_merge(inverted_index['group'],inverted_index['team']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Similarly as above, implement the function `or_merge` outlined below that executes an OR merging of the lists. The resulting list should therefore include all the elements that appear in at least one of the lists. Again, this operation should take advantage of the input lists being sorted already, should not perform any additional sorting operation, and should go through each of the input lists just once. Elements that appear in both input list should only appear once in the output list. Test your function again with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9309949, 12887631, 16916569, 22419565, 31854264, 34512487, 1, 6, 9756244, 16916567, 21859206, 25186285, 26784347, 29218587, 29406610, 33741990]\n"
     ]
    }
   ],
   "source": [
    "def or_merge(sorted_list1, sorted_list2):\n",
    "    merged_list = []\n",
    "    # first we make copies of the lists, so we don't modify the existing lists in the index:\n",
    "    list1 = list(sorted_list1)\n",
    "    list2 = list(sorted_list2)\n",
    "\n",
    "    for id in list1: merged_list.append(id)\n",
    "\n",
    "    for id in list2:\n",
    "        if id in merged_list: continue\n",
    "        \n",
    "        merged_list.append(id)\n",
    "\n",
    "    return merged_list\n",
    "\n",
    "# testing:\n",
    "print(or_merge(sampl1,sample2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Construct a function called `and_query` that takes as input a single string, consisting of one or more words, and returns as function value a list of matching documents. `and_query`, as its name suggests, should require that all query terms are present in the documents of the result list.\n",
    "\n",
    "For that, access the variable `inverted_index` from above and use the method `and_merge` that you defined. Also use the `tokenize` and `preprocess` functions we defined above to tokenize and preprocess your query.\n",
    "\n",
    "Again demonstrate the working of your function with an example (choose one that leads to fewer than 100 hits to not overblow this notebook file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2238970, 6858287, 11478037, 24712897, 30534094, 30711434]\n"
     ]
    }
   ],
   "source": [
    "def and_query(query, docs=[]):\n",
    "\tif type(query) == str:\t\t#initial state where query is a string\n",
    "\t\tquery = preprocess(tokenize(query))\n",
    "\t\tdocs.extend(inverted_index[query[0]]) #fill docs with documnts that include only the first term to be able to compare with something later one in the recursion\n",
    "\n",
    "\tif len(query) <= 1:  #'bottom\" of recursion where there's only one term left\n",
    "\t\treturn and_merge(docs,inverted_index[query[0]])\n",
    "\telse:\n",
    "\t\tdocs = and_merge(docs, inverted_index[query[0]]) #find common docs between already found document and documets including the next term - for the firt 'iteraion' docs and the term are the same documents\n",
    "\n",
    "\t\treturn and_query(query[1:], docs) #run and_query again with all the query exluding the current first term\n",
    "\n",
    "\n",
    "print(and_query('scientific emotion deal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Construct another function called `or_query` that works in the same way as `and_query` you just implemented, but returns as function value the documents that contain _at least one_ of the words in the query, using the `or_merge` function you defined.\n",
    "\n",
    "Demonstrate the working of this function also with an example (again, choose one that leads to fewer than 100 hits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16938038,\n",
       " 22862968,\n",
       " 25797829,\n",
       " 32853011,\n",
       " 34177648,\n",
       " 34554917,\n",
       " 16938038,\n",
       " 22862968,\n",
       " 25797829,\n",
       " 32853011,\n",
       " 34177648,\n",
       " 34554917,\n",
       " 9756244,\n",
       " 16916567,\n",
       " 21859206,\n",
       " 25186285,\n",
       " 26784347,\n",
       " 29218587,\n",
       " 29406610,\n",
       " 33741990]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def or_query(query, docs=[]):\n",
    "\tif type(query) == str:\t\t#initial state where query is a string\n",
    "\t\tquery = preprocess(tokenize(query))\n",
    "\t\tdocs.extend(inverted_index[query[0]]) #fill docs with documnts that include only the first term to be able to compare with something later one in the recursion\n",
    "\n",
    "\tif len(query) <= 1:  #'bottom\" of recursion where there's only one term left\n",
    "\t\treturn or_merge(docs,inverted_index[query[0]])\t\n",
    "\n",
    "\tdocs.extend(or_merge(docs, inverted_index[query[0]])) #find common docs between already found document and documets including the next term - for the firt 'iteraion' docs and the term are the same documents\n",
    "\n",
    "\treturn or_query(query[1:], docs) #run and_query again with all the query exlusing the current first term\n",
    "\n",
    "or_query('athens amsterdam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Why does `and_query('emotional factor experiment')` not return our example paper 34648542, even though it mentions emotional factors and experiments in the abstract? (You do not have to implement anything to fix this yet!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** [Write your answer text here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to the assignment via Canvas as a modified version of this Notebook file (file with `.ipynb` extension) that includes your code and your answers.\n",
    "\n",
    "Before submitting, restart the kernel and re-run the complete code (**Kernel > Restart & Run All**), and then check whether your assignment code still works as expected.\n",
    "\n",
    "Don't forget to add your name, and remember that the assignments have to be done **individually**, and that code sharing or copying are **strictly forbidden** and will be punished."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
