{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Link Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will use network-based algorithms, such as PageRank, to improve our search results. After the last assignment on evaluating IR systems, we go back to our PubMed dataset of scientific papers. In this dataset, we look at two graphs in particular: the co-authorship network and the citation network.\n",
    "\n",
    "The citation network is similar to the link network of the web: Citations are like web links pointing to other documents. We can therefore apply the same network-based ranking methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from previous assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2\n",
    "from collections import defaultdict, namedtuple, Counter\n",
    "from math import log10, sqrt\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show plots inline within the notebook\n",
    "%matplotlib inline\n",
    "# set plots' resolution\n",
    "plt.rcParams['savefig.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids_file = 'data/emotion_Ids.pkl.bz2'\n",
    "Summaries_file = 'data/emotion_Summaries.pkl.bz2'\n",
    "Citations_file = 'data/emotion_Citations.pkl.bz2'\n",
    "Abstracts_file = 'data/emotion_Abstracts.pkl.bz2'\n",
    "\n",
    "Ids = pickle.load( bz2.BZ2File( Ids_file, 'rb' ) )\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "Citations = pickle.load( bz2.BZ2File( Citations_file, 'rb' ) )\n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary( id, show_abstract=False, show_id=True, extra_text='' ):\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long author lists, and adds a link to the paper's DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[id]\n",
    "    lines = []\n",
    "    title = s.title\n",
    "    if s.doi != '':\n",
    "        title = '<a href=http://dx.doi.org/{:s}>{:s}</a>'.format(s.doi, title)\n",
    "    title = '<strong>' + title + '</strong>'\n",
    "    lines.append(title)\n",
    "    authors = ', '.join( s.authors[:20] ) + ('' if len(s.authors) <= 20 else ', ...')\n",
    "    lines.append(str(s.year) + '. ' + authors)\n",
    "    if (show_abstract):\n",
    "        lines.append('<small><strong>Abstract:</strong> <em>{:s}</em></small>'.format(Abstracts[id]))\n",
    "    if (show_id):\n",
    "        lines.append('[ID: {:d}]'.format(id))\n",
    "    if (extra_text != ''):\n",
    "         lines.append(extra_text)\n",
    "    display( HTML('<br>'.join(lines)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = defaultdict(list)\n",
    "\n",
    "for id in sorted(Summaries.keys()):\n",
    "    term_set = set(preprocess(tokenize(Summaries[id].title)))\n",
    "    if id in Abstracts:\n",
    "        term_set.update(preprocess(tokenize(Abstracts[id])))\n",
    "    for term in term_set:\n",
    "        inverted_index[term].append(id)\n",
    "\n",
    "tf_matrix = defaultdict(Counter)\n",
    "\n",
    "for doc_id in Summaries.keys():\n",
    "    tokens = preprocess(tokenize(Summaries[doc_id].title))\n",
    "    if (doc_id in Abstracts):\n",
    "        tokens.extend(preprocess(tokenize(Abstracts[doc_id])))\n",
    "    tf_matrix[doc_id] = Counter(tokens)\n",
    "\n",
    "def tf(t,d):\n",
    "    return float(tf_matrix[d][t])\n",
    "\n",
    "def df(t):\n",
    "    return float(len(inverted_index[t]))\n",
    "\n",
    "num_documents = float(len(Summaries))\n",
    "\n",
    "def idf(t):\n",
    "    return log10((num_documents + 1)/(df(t) + 1))\n",
    "\n",
    "def tfidf(t,d):\n",
    "    return tf(t,d) * idf(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-authorship network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by building a mapping from authors to the set of identifiers of papers they authored.  We'll be using Python sets again for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_of_author = defaultdict(set)\n",
    "\n",
    "for (id, p) in Summaries.items():\n",
    "    for a in p.authors:\n",
    "        papers_of_author[a].add(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9309949, 17760288, 31649584}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_of_author['Eriksen HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.3389/fpsyg.2019.02233>Occupational Rehabilitation Is Associated With Improvements in Cognitive Functioning.</a></strong><br>2019. Johansen T, Jensen C, Eriksen HR, Lyby PS, Dittrich WH, Holsen IN, Jakobsen H, Øyeflaten I<br>[ID: 31649584]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Psychological selection of Antarctic personnel: the \"SOAP\" instrument.</strong><br>2007. Grant I, Eriksen HR, Marquis P, Orre IJ, Palinkas LA, Suedfeld P, Svensen E, Ursin H<br>[ID: 17760288]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1111/1467-9450.00025>The CODE: a revised battery for coping and defense and its relations to subjective health.</a></strong><br>1997. Eriksen HR, Olff M, Ursin H<br>[ID: 9309949]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for id in papers_of_author['Eriksen HR']:\n",
    "    display_summary(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build a co-authorship network, that is a graph linking authors to the set of co-authors they have published with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthors = defaultdict(set)\n",
    "\n",
    "for p in Summaries.values():\n",
    "    for a in p.authors:\n",
    "        coauthors[a].update(p.authors)\n",
    "\n",
    "# The code above results in each author being listed as having co-authored with himself/herself.\n",
    "# We remove these self-references here:\n",
    "for (a, ca) in coauthors.items():\n",
    "    ca.remove(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try it out again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen T, Lyby PS, Dittrich WH, Øyeflaten I, Orre IJ, Ursin H, Grant I, Palinkas LA, Jakobsen H, Suedfeld P, Svensen E, Holsen IN, Jensen C, Olff M, Marquis P\n"
     ]
    }
   ],
   "source": [
    "print(', '.join( coauthors['Eriksen HR'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike a citation or link network, the edges of this co-authorship network are not directed: There is no direction (no arrow) in the link between author 'Eriksen HR' and 'Suedfeld P', for example. With our chosen implementation, each of these links in fact appears twice in our data, as we also get 'Eriksen HR' as co-author when we look for 'Suedfeld P':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orre IJ, Ursin H, Grant I, Palinkas LA, Eriksen HR, Svensen E, Marquis P\n"
     ]
    }
   ],
   "source": [
    "print(', '.join( coauthors['Suedfeld P'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in mind, we can calculate some basic statistics about our graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes (authors):  99675\n",
      "Number of links (co-authorship relations):  590848\n"
     ]
    }
   ],
   "source": [
    "print('Number of nodes (authors): ', len(coauthors))\n",
    "\n",
    "# We divide by two here to account for the fact that each edge is represented twice (see above):\n",
    "coauthor_rel_count = int(sum( len(c) for c in coauthors.values() ) / 2)\n",
    "print('Number of links (co-authorship relations): ', coauthor_rel_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data at hand, we can plot the [degree distribution](https://en.wikipedia.org/wiki/Degree_distribution) by showing the number of collaborators a scientist has published with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( x=[ len(ca) for ca in coauthors.values() ], bins=range(60) )\n",
    "plt.xlabel('number of co-authors')\n",
    "plt.ylabel('number of researchers')\n",
    "plt.xlim(0,51);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have explored this network, let's move to the citation network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can look at the citation network. In contrast to the co-authorship network, the citation network is a _directed_ network, where edges can be drawn as arrows. We'll start by expanding the our data about citations into two mappings: \n",
    "\n",
    "* `papers_citing[id]`: papers citing a given paper\n",
    "* `cited_by[id]`: papers cited by a given paper (in other words: its list of references)\n",
    "\n",
    "`papers_citing` will give us the list of a node's incoming links, whereas `cited_by` will give us the list of its outgoing links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_citing = Citations  # no changes needed, this is what we are storing already in the Citations dataset\n",
    "\n",
    "cited_by = defaultdict(list)\n",
    "\n",
    "for ref, papers_citing_ref in papers_citing.items():\n",
    "    for id in papers_citing_ref:\n",
    "        cited_by[ id ].append( ref )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are dealing with a subset of the data (the papers mentioning \"emotion\"), `papers_citing` can contain references to papers outside of our subset. On the other hand, the way we created `cited_by`, it will only contain backward references from within our dataset, meaning that it is incomplete with respect to the whole dataset. Nethertheless, we can use this citation network on our subset of emotion-related papers to implement link analysis techniques.\n",
    "\n",
    "Let us now look at an exemplary paper, let's say the one with identifier 26784347. We can now use the `cited_by` mapping to retrieve its (incomplete) list of references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 references found for paper 26784347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{24708508: 'Judgments of subtle facial expressions of emotion.',\n",
       " 24388852: 'Dynamic facial expressions of emotion transmit an evolving hierarchy of signals over time.',\n",
       " 23659578: 'Classification of dynamic facial expressions of emotion presented briefly.',\n",
       " 22876223: 'Attention and awareness each influence amygdala activity for dynamic bodily expressions-a short review.',\n",
       " 22131445: 'The resolution of facial expressions of emotion.',\n",
       " 22081890: 'Introducing the Geneva Multimodal expression corpus for experimental research on emotion perception.',\n",
       " 21859206: 'Moving faces, looking places: validation of the Amsterdam Dynamic Facial Expression Set (ADFES).',\n",
       " 20809200: 'Facial emotion recognition in autism spectrum disorders: a review of behavioral and neuroimaging studies.',\n",
       " 19884144: 'The face is not an empty canvas: how facial expressions interact with facial appearance.',\n",
       " 19803591: 'Emotion recognition from expressions in face, voice, and body: the Multimodal Emotion Recognition Test (MERT).',\n",
       " 19653779: 'Development of a FACS-verified set of basic and self-conscious emotion expressions.',\n",
       " 19501062: 'Emotions in motion: dynamic compared to static facial expressions of disgust and happiness reveal more widespread emotion-specific activations.',\n",
       " 18598725: 'Enhanced facial EMG activity in response to dynamic facial expressions.',\n",
       " 18495094: 'Audio-visual integration of emotion expression.',\n",
       " 18411533: 'Facial expressions of emotion (KDEF): identification under different display-duration conditions.',\n",
       " 18405043: 'Dynamic facial expressions of emotion induce representational momentum.',\n",
       " 18266518: 'The automaticity of emotion recognition.',\n",
       " 18191116: 'Neural circuitry for accurate identification of facial emotions.',\n",
       " 17715585: 'Recognizing emotion from facial expressions: psychological and neurological mechanisms.',\n",
       " 17583430: 'Recognition and discrimination of prototypical dynamic expressions of pain and emotions.',\n",
       " 17566449: 'The Emotion Recognition Task: a paradigm to measure the perception of facial emotional expressions at different intensities.',\n",
       " 17535474: 'Role of motion signals in recognizing subtle facial expressions of emotion.',\n",
       " 15993402: 'Measuring individual differences in sensitivities to basic emotions in faces.',\n",
       " 15491276: 'The relationship among expressions, labels, and descriptions of contempt.',\n",
       " 15130592: 'Enhanced neural activity in response to dynamic facial expressions of emotion: an fMRI study.',\n",
       " 12974567: 'Recognising facial expression from spatially and temporally modified movements.',\n",
       " 12899416: 'What do facial expressions convey: feeling states, behavioral intentions, or action requests?',\n",
       " 12899367: 'Cross-cultural patterns in emotion recognition: highlighting design and analytical techniques.',\n",
       " 11931516: 'On the universality and cultural specificity of emotion recognition: a meta-analysis.',\n",
       " 11515959: 'Dynamic properties influence the perception of facial expressions.',\n",
       " 10856740: 'Caricaturing facial expressions.',\n",
       " 9265191: 'Computer-enhanced emotion in facial expressions.',\n",
       " 8851745: 'Acoustic profiles in vocal emotion expression.',\n",
       " 7861316: 'Components and recognition of facial expression in the communication of emotion by actors.',\n",
       " 7962581: 'Measuring emotion: the Self-Assessment Manikin and the Semantic Differential.',\n",
       " 1506820: 'Neural and behavioral correlates of emotion recognition in children and adults.',\n",
       " 1669960: \"What's basic about basic emotions?\",\n",
       " 5542557: 'Constants across cultures in the face and emotion.',\n",
       " 5773719: 'Pan-cultural elements in facial displays of emotion.'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_id = 26784347\n",
    "refs = { id : Summaries[id].title for id in cited_by[paper_id] }\n",
    "print(len(refs), 'references found for paper', paper_id)\n",
    "refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we lookup the same paper in `papers_citing`, we now see that some of the cited papers are themselves in our dataset, but others are not (shown below as `'??'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34138924: '??',\n",
       " 33958630: 'The paradoxical role of emotional intensity in the perception of vocal affect.',\n",
       " 33930026: 'SUST Bangla Emotional Speech Corpus (SUBESCO): An audio-only emotional speech corpus for Bangla.',\n",
       " 33053797: 'Recognizing Emotions through Facial Expressions: A Largescale Experimental Study.',\n",
       " 32804342: 'Human and machine validation of 14 databases of dynamic facial expressions.',\n",
       " 32170180: 'Perception of Discrete Emotions in Others: Evidence for Distinct Facial Mimicry Patterns.',\n",
       " 31762947: 'Are you angry at me? Negative interpretations of neutral facial expressions are linked to child maltreatment but not to posttraumatic stress disorder.',\n",
       " 31258497: 'Development and Validation of Verbal Emotion Vignettes in Portuguese, English, and German.',\n",
       " 30800085: '??',\n",
       " 29928240: \"Incongruence Between Observers' and Observed Facial Muscle Activation Reduces Recognition of Emotional Facial Expressions From Video Stimuli.\",\n",
       " 29370198: 'Gender differences in emotion perception and self-reported emotional intelligence: A test of the emotion sensitivity hypothesis.',\n",
       " 29293674: 'Sex differences in facial emotion recognition across varying expression intensity levels from videos.',\n",
       " 27977795: '??'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ id : Summaries.get(id,['??'])[0]  for id in papers_citing[paper_id] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper 34138924, for example, is not in our dataset and we do not have any direct information about it, but its repeated occurrence in other papers' citation lists does allow us to reconstruct some of its references. Below is the list of papers in our dataset cited by that paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 references identified for the paper with id 34138924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{32804342: 'Human and machine validation of 14 databases of dynamic facial expressions.',\n",
       " 31834900: 'The effect of emotional information from eyes on empathy for pain: A subliminal ERP study.',\n",
       " 31622426: 'Assessing the convergent validity between the automated emotion recognition software Noldus FaceReader 7 and Facial Action Coding System Scoring.',\n",
       " 30744534: \"Validating the Radboud faces database from a child's perspective.\",\n",
       " 30589868: \"Subjective ratings and emotional recognition of children's facial expressions from the CAFE set.\",\n",
       " 30273355: 'Cross-cultural emotion recognition and evaluation of Radboud faces database with an Indian sample.',\n",
       " 29218587: 'Facial expression analysis with AFFDEX and FACET: A validation study.',\n",
       " 28553255: 'Development of the Korean Facial Emotion Stimuli: Korea University Facial Expression Collection 2nd Edition.',\n",
       " 26784347: 'Validation of the Amsterdam Dynamic Facial Expression Set--Bath Intensity Variations (ADFES-BIV): A Set of Videos Expressing Low, Intermediate, and High Intensity Emotions.',\n",
       " 26479048: 'Development and validation of an Argentine set of facial expressions of emotion.',\n",
       " 26157405: 'The adaptive value associated with expressing and perceiving angry-male and happy-female faces.',\n",
       " 25601846: 'Warsaw set of emotional facial expression pictures: a validation study of facial display photographs.',\n",
       " 24238931: 'Biased processing of neutral facial expressions is associated with depressive symptoms and suicide ideation in individuals at risk for major depression due to affective temperaments.',\n",
       " 23196633: 'Reduced emotion processing efficiency in healthy males relative to females.',\n",
       " 22509011: 'Facial expressions of emotion are not culturally universal.',\n",
       " 22503384: 'The Chinese Facial Emotion Recognition Database (CFERD): a computer-generated 3-D paradigm to measure the recognition of facial emotional expressions at different intensities.',\n",
       " 20160315: 'FACES--a database of facial expressions in young, middle-aged, and older women and men: development and validation.',\n",
       " 19803591: 'Emotion recognition from expressions in face, voice, and body: the Multimodal Emotion Recognition Test (MERT).',\n",
       " 8512154: 'Facial expression and emotion.',\n",
       " 5773719: 'Pan-cultural elements in facial displays of emotion.'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_id2 = 34138924\n",
    "refs2 = { id : Summaries[id].title for id in cited_by[paper_id2] }\n",
    "print(len(refs2), 'references identified for the paper with id', paper_id2)\n",
    "refs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better understanding about the data we're dealing with, let us obtain again some basic statistics about our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in our subset: 46483 (100.00 %)\n",
      "Number of papers cited at least once: 35018 (75.34 %)\n",
      "Number of isolated nodes:  8737 (18.80 %)\n"
     ]
    }
   ],
   "source": [
    "n = len(Ids)\n",
    "print('Number of papers in our subset: {:d} ({:.2f} %)'.format(n, 100.0) )\n",
    "\n",
    "with_citation = [ id for id in Ids if papers_citing[id] != [] ]\n",
    "with_citation_rel = 100. * len(with_citation) / n\n",
    "print('Number of papers cited at least once: {:d} ({:.2f} %)'.format(len(with_citation), with_citation_rel) )\n",
    "\n",
    "isolated = set( id for id in Ids if papers_citing[id] == [] and id not in cited_by )\n",
    "isolated_rel = 100. * len(isolated) / n\n",
    "print('Number of isolated nodes:  {:d} ({:.2f} %)'.format(len(isolated), isolated_rel) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall number of nodes: 221889 (100.00 %)\n",
      "Number of non-isolated nodes: 213152 (96.06 %)\n",
      "Number of nodes outside our subset: 175406 (79.05 %)\n"
     ]
    }
   ],
   "source": [
    "id_set = set( Ids )\n",
    "citing_set = set( cited_by.keys() )\n",
    "\n",
    "outsiders = citing_set - id_set   # set difference\n",
    "nodes = citing_set | id_set   # set union\n",
    "non_isolated = nodes - isolated   # set difference\n",
    "\n",
    "print('Overall number of nodes: {:d} ({:.2f} %)'.format(len(nodes), 100.0) )\n",
    "\n",
    "non_isolated_rel = 100. * len(non_isolated) / len(nodes)\n",
    "print('Number of non-isolated nodes: {:d} ({:.2f} %)'.format(len(non_isolated), non_isolated_rel) )\n",
    "\n",
    "outsiders_rel = 100. * len(outsiders) / len(nodes)\n",
    "print('Number of nodes outside our subset: {:d} ({:.2f} %)'.format( len(outsiders), outsiders_rel ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall number of links (citations): 562891 (100.00 %)\n",
      "Citations outside the subset: 401831 (71.39 %)\n"
     ]
    }
   ],
   "source": [
    "all_citations = [ c for citing in papers_citing.values() for c in citing ]\n",
    "outsider_citations = [ c for citing in papers_citing.values() for c in citing if c in outsiders ]\n",
    "\n",
    "print('Overall number of links (citations): {:d} ({:.2f} %)'.format(len(all_citations), 100.0) )\n",
    "\n",
    "outsider_citations_rel = 100. * len(outsider_citations) / len(all_citations)\n",
    "print('Citations outside the subset: {:d} ({:.2f} %)'.format(len(outsider_citations), outsider_citations_rel) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now find our which 10 papers are the most cited in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1146/annurev.neuro.23.1.155>Emotion circuits in the brain.</a></strong><br>2000. LeDoux JE<br>[ID: 10845062]<br>Citation count: 2034"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1016/s1364-6613(00)01483-2>Cognitive and emotional influences in anterior cingulate cortex.</a></strong><br>2000. Bush G, Luu P, Posner MI<br>[ID: 10827444]<br>Citation count: 1633"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1038/nrn894>How do you feel? Interoception: the sense of the physiological condition of the body.</a></strong><br>2002. Craig AD<br>[ID: 12154366]<br>Citation count: 1443"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1037/0022-3514.85.2.348>Individual differences in two emotion regulation processes: implications for affect, relationships, and well-being.</a></strong><br>2003. Gross JJ, John OP<br>[ID: 12916575]<br>Citation count: 1182"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1016/j.tics.2005.03.010>The cognitive control of emotion.</a></strong><br>2005. Ochsner KN, Gross JJ<br>[ID: 15866151]<br>Citation count: 1181"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1016/0005-7916(94)90063-9>Measuring emotion: the Self-Assessment Manikin and the Semantic Differential.</a></strong><br>1994. Bradley MM, Lang PJ<br>[ID: 7962581]<br>Citation count: 1064"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1176/appi.ajp.2007.07030504>Functional neuroimaging of anxiety: a meta-analysis of emotional processing in PTSD, social anxiety disorder, and specific phobia.</a></strong><br>2007. Etkin A, Wager TD<br>[ID: 17898336]<br>Citation count: 1012"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1038/nn1176>Neural systems supporting interoceptive awareness.</a></strong><br>2004. Critchley HD, Wiens S, Rotshtein P, Ohman A, Dolan RJ<br>[ID: 14730305]<br>Citation count: 963"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1016/j.tics.2010.11.004>Emotional processing in anterior cingulate and medial prefrontal cortex.</a></strong><br>2011. Etkin A, Egner T, Kalisch R<br>[ID: 21167765]<br>Citation count: 957"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1016/j.neuron.2005.09.025>Contributions of the amygdala to emotion processing: from animal models to human behavior.</a></strong><br>2005. Phelps EA, LeDoux JE<br>[ID: 16242399]<br>Citation count: 950"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "citation_count_per_paper = [ (id, len(citations)) for (id,citations) in papers_citing.items() ]\n",
    "sorted_by_citation_count = sorted(citation_count_per_paper, key=lambda i:i[1], reverse=True)\n",
    "\n",
    "for (id, c) in sorted_by_citation_count[:10]:\n",
    "    display_summary(id, extra_text = 'Citation count: ' + str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start calculating some interesting network metrics, we will first have a closer look at the Python package that we are going to use for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Analysis for Search Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the citation network, we need to be able to perform some complex graph algorithms on it. To make our lives easier, we will use [NetworkX](https://pypi.python.org/pypi/networkx), a Python package for dealing with complex networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /Users/nikitasfilosofof/Library/Python/3.9/lib/python/site-packages (2.6.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install --user networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph(cited_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a NetworkX Directed Graph stored in `G`, where a node represents a paper, and an edge represents a citation. This means we can now apply the [algorithms](http://networkx.github.io/documentation/networkx-1.10/reference/algorithms.html) and [functions](http://networkx.github.io/documentation/networkx-1.10/reference/functions.html) of NetworkX to our graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 213152 nodes and 562891 edges\n",
      "Directed graph: True\n",
      "Density of graph: 1.2389321369843012e-05\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))\n",
    "print('Directed graph:', nx.is_directed(G))\n",
    "print('Density of graph:', nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this graph was generated from citations only, we need to add all isolated nodes (nodes that are not cited and do not cite other papers) as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(isolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we get slightly different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 221889 nodes and 562891 edges\n",
      "Directed graph: True\n",
      "Density of graph: 1.1432855547712948e-05\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))\n",
    "print('Directed graph:', nx.is_directed(G))\n",
    "print('Density of graph:', nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use this package for our tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** Nikitas Filosofof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Plot the in-degree distribution (that is, the distribution of the number of incoming links; see [here](https://en.wikipedia.org/wiki/Degree_distribution) and [here](http://mathinsight.org/degree_distribution) for more detailed explanations) for the citation network. What can you tell about the shape of this distribution, and what does this tell us about the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( x=[ len(inc_links) for inc_links in papers_citing.values() ], bins=range(60) )\n",
    "plt.xlabel('number of papers')\n",
    "plt.ylabel('number of incoming links')\n",
    "plt.xlim(0,51);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** It's a very right-skewed histogram, and from it we can tell that most papers have no incoming links whatsoever\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Using the [Link Analysis](https://networkx.org/documentation/stable/reference/algorithms/link_analysis.html) algorithms provided by NetworkX, calculate the PageRank score for all nodes in the citation network, and store the result in a variable called `pageranks`.\n",
    "\n",
    "To test this, create first a list of all papers that are cited by exactly 10 other papers (using `papers_citing` defined above). Then sort these papers by their PageRank and retrieve the paper IDs with the maximum and minimum PageRank values. Print these minimum and maximum PageRank values together with their paper IDs.\n",
    "\n",
    "To print PageRank values, you might want to use commands like `print('{:.6f}'.format(var))` to use regular decimal notation with a fixed number of decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "pageranks = nx.link_analysis.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value is:  0.0000379816 from document:  12382205\n",
      "Minimum value is:  0.0000030449 from document:  28402574\n"
     ]
    }
   ],
   "source": [
    "papers_10_incoming = [id for id, inc_links in papers_citing.items() if len(inc_links) ==10]\n",
    "\n",
    "ranked = {}\n",
    "for paper in papers_10_incoming:\n",
    "\tranked[paper] = pageranks[paper]\n",
    "\n",
    "ranked = sorted(ranked.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Maximum value is: \", '{:.10f}'.format(ranked[0][1]), \"from document: \", ranked[0][0])\n",
    "print(\"Minimum value is: \", '{:.10f}'.format(ranked[-1][1]), \"from document: \", ranked[-1][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Why do the two papers above have such different PageRank values? Write code below to investigate and show the cause of this, and then explain the cause of this difference based on the results generated by your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "9.517480542279814e-06 3.3997988956590496e-06\n"
     ]
    }
   ],
   "source": [
    "#First i'll investigate their incoming links\n",
    "links_to_max = papers_citing[12382205]\n",
    "links_to_min = papers_citing[28402574]\n",
    "print(len(links_to_max), len(links_to_min))\n",
    "#Turns out they have the same number of links\n",
    "#I just realized that's because the whole subset is with papers with the same number of links\n",
    "\n",
    "#I'll check the average pagerank of their incoming links\n",
    "max_authority = 0\n",
    "for doc in links_to_max:\n",
    "\tmax_authority += pageranks[doc]\n",
    "\n",
    "min_authority = 0\n",
    "for doc in links_to_min:\n",
    "\tmin_authority += pageranks[doc]\n",
    "\n",
    "print(max_authority/10, min_authority/10)\n",
    "#Aha! The average rank of the document linking to the maximum one, are way more important than the ones pointing to the min. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** The average rank of the documents linking to the maximum one are way more important than the ones pointing to the min. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Copy the scoring function `score_ntn_nnn` from Task 4 of assignment 3. Rename it to `score_ntn_nnn_pagerank` and change its code to incorporate a paper's PageRank score in it's final score, in addition to tf-idf. In other words, the new function should accept a `list` of query tokens and a document ID, and should return a single `float` value that is calculated based on both scores (PageRank and tf-idf). Note that a `tf-idf` function is already provided above. Explain your decision on how to combine the two scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013447693490362437\n"
     ]
    }
   ],
   "source": [
    "def score_ntn_nnn_pagerank(query_words, doc_id):\n",
    "\tresult = 0\n",
    "\n",
    "\tfor term in query_words:\n",
    "\t\tresult += tfidf(term, doc_id)\n",
    "\n",
    "\treturn result * pageranks[doc_id]\n",
    "\n",
    "print(score_ntn_nnn_pagerank(['emotion', 'women'], 22571249))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** Page rank is an paper authority measure thus it should act as a moderator of the ranking. Multipling the a paper's rank by it's ntn.nnn score gives us the most important documents from those that are most relevant to a given topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Copy the query function `query_ntn_nnn` from Task 4 of assignment 3 (also copy `or_merge`). Rename it to `query_ntn_nnn_pagerank` and change the code to use our new scoring function `score_ntn_nnn_pagerank` from task 4 above. Demonstrate these functions with an example query that returns paper 16242399 as the top result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_merge(sorted_list1, sorted_list2):\n",
    "    merged_list = []\n",
    "    list1 = list(sorted_list1)\n",
    "    list2 = list(sorted_list2)\n",
    "    while (True):\n",
    "        if (not list1):\n",
    "            merged_list.extend(list2)\n",
    "            break\n",
    "        if (not list2):\n",
    "            merged_list.extend(list1)\n",
    "            break\n",
    "        if (list1[0] < list2[0]):\n",
    "            merged_list.append(list1[0])\n",
    "            list1.pop(0)\n",
    "        elif (list1[0] > list2[0]):\n",
    "            merged_list.append(list2[0])\n",
    "            list2.pop(0)\n",
    "        else:\n",
    "            merged_list.append(list1[0])\n",
    "            list1.pop(0)\n",
    "            list2.pop(0)\n",
    "    return merged_list\n",
    "\n",
    "def or_query(query_string):\n",
    "    query_words = preprocess(tokenize(query_string))\n",
    "    first_word = query_words[0]\n",
    "    remaining_words = query_words[1:]\n",
    "    or_list = inverted_index[first_word]\n",
    "    for t in remaining_words:\n",
    "        or_list = or_merge(or_list, inverted_index[t])\n",
    "    return or_list\n",
    "\n",
    "def query_ntn_nnn_pagerank(query_string):\n",
    "\tdocs = or_query(query_string)\n",
    "\tterms = preprocess(tokenize(query_string))\n",
    "\tdoc_weights = defaultdict(set)\n",
    "\tfor doc_id in docs:\n",
    "\t\tdoc_weights[doc_id] = score_ntn_nnn_pagerank(terms, doc_id)\t\n",
    "\n",
    "\treturn dict(sorted(doc_weights.items(), key=lambda x:x[1],reverse=True)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16242399: 0.0061094140346399884,\n",
       " 12505650: 0.00589270329832829,\n",
       " 10377356: 0.005532961342110747,\n",
       " 11244481: 0.005471414297617973,\n",
       " 16624961: 0.004554925524024069,\n",
       " 8893004: 0.004527062007258105,\n",
       " 15880108: 0.003615265613848397,\n",
       " 10845062: 0.003504411683416224,\n",
       " 12453496: 0.0029549853185168702,\n",
       " 10827444: 0.002866964093239108}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_ntn_nnn_pagerank('amygdala emotional processing activates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to the assignment via Canvas as a modified version of this Notebook file (file with `.ipynb` extension) that includes your code and your answers.\n",
    "\n",
    "Before submitting, restart the kernel and re-run the complete code (**Kernel > Restart & Run All**), and then check whether your assignment code still works as expected.\n",
    "\n",
    "Don't forget to add your name, and remember that the assignments have to be done **individually**, and that code sharing or copying are **strictly forbidden** and will be punished."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
