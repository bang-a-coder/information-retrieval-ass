{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Building a Simple Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will build a simple search index, which we will use later for Boolean retrieval. The assignment tasks are again at the bottom of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summaries_file = 'data/emotion_Summaries.pkl.bz2'\n",
    "Abstracts_file = 'data/emotion_Abstracts.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2\n",
    "from collections import namedtuple\n",
    "\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )\n",
    "    \n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what the data looks like for an example of a paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summaries[34648542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstracts[34648542]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define some utility functions that allow us to tokenize a string into terms, perform linguistic preprocessing on a list of terms, as well as a function to display information about a paper in a nice way. Note that these tokenization and preprocessing functions are rather naive. We will improve them in a later assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function that tokenizes a string in a rather naive way. Can be extended later.\n",
    "    \"\"\"\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    \"\"\"\n",
    "    Perform linguistic preprocessing on a list of tokens. Can be extended later.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result\n",
    "\n",
    "print(preprocess(tokenize(\"Lorem ipsum dolor sit AMET\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import re\n",
    "\n",
    "def display_summary( id, show_abstract=False, show_id=True, extra_text='' ):\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long author lists, and adds a link to the paper's DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[id]\n",
    "    lines = []\n",
    "    title = s.title\n",
    "    if s.doi != '':\n",
    "        title = '<a href=http://dx.doi.org/{:s}>{:s}</a>'.format(s.doi, title)\n",
    "    title = '<strong>' + title + '</strong>'\n",
    "    lines.append(title)\n",
    "    authors = ', '.join( s.authors[:20] ) + ('' if len(s.authors) <= 20 else ', ...')\n",
    "    lines.append(str(s.year) + '. ' + authors)\n",
    "    if (show_abstract):\n",
    "        lines.append('<small><strong>Abstract:</strong> <em>{:s}</em></small>'.format(Abstracts[id]))\n",
    "    if (show_id):\n",
    "        lines.append('[ID: {:d}]'.format(id))\n",
    "    if (extra_text != ''):\n",
    "         lines.append(extra_text)\n",
    "    display( HTML('<br>'.join(lines)) )\n",
    "\n",
    "display_summary(34648542)\n",
    "display_summary(34648542, show_abstract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our first index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create an _inverted index_ based on the words in the titles and abstracts of the papers in our dataset. We will implement our inverted index as a Python dictionary with term strings as keys and posting lists (implemented as Python lists) as values. We include all the tokens we can find in the title and (if available) in the abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summaries.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "inverted_index = defaultdict(list)\n",
    "\n",
    "# This can take a few seconds:\n",
    "for id in sorted(Summaries.keys()):\n",
    "    term_set = set(preprocess(tokenize(Summaries[id].title)))\n",
    "    if id in Abstracts:\n",
    "        term_set.update(preprocess(tokenize(Abstracts[id])))\n",
    "    for term in term_set:\n",
    "        inverted_index[term].append(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what's in the index for the example term 'amsterdam':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverted_index['amsterdam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this inverted index to answer simple one-word queries, for example to show all papers that contain the word 'utrecht':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_word = 'utrecht'\n",
    "for i in inverted_index[query_word]:\n",
    "    display_summary(i, show_abstract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** Nikitas Filosofof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverted_index['utrecht'],inverted_index['amsterdam'])\n",
    "\n",
    "min((inverted_index['utrecht'],inverted_index['amsterdam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Implement the function `and_merge` outlined below. This function takes two posting lists from the index that can be assumed to be sorted already, and it should return the result of the merging of the two lists with AND. The resulting list should therefore include all the elements that appear in both lists. As explained on the slides, this operation should take advantage of the input lists being sorted already, should not perform any additional sorting operation, and should go through each of the input lists just once. Then, test your function with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_merge(sorted_list1, sorted_list2):\n",
    "    merged_list = []\n",
    "    # first we make copies of the lists, so we don't modify the existing lists in the index:\n",
    "    list1 = list(sorted_list1)\n",
    "    list2 = list(sorted_list2)\n",
    "\n",
    "    #iterators\n",
    "    it_1 = 0\n",
    "    it_2 = 0\n",
    "\n",
    "    while it_1 < len(list1) and it_2 < len(list2): #  checking if it exceeds the max len of any list, merge_list can have at most len(min(sorted_list1,sorted_list2)) elements\n",
    "        if list1[it_1] == list2[it_2]:\n",
    "            merged_list.append(list1[it_1])\n",
    "            it_1 += 1\n",
    "            it_2 += 1\n",
    "        elif list1[it_1] < list2[it_2]:\n",
    "            it_1 += 1\n",
    "        else:\n",
    "            it_2 += 1\n",
    "\n",
    "    return merged_list\n",
    "\n",
    "sampl1= [4,9309949, 12887631, 16916569, 22419565, 31854264, 34512487] \n",
    "sample2= [1,4,6,6,6,6,6,6,6,6,6,9756244, 16916567, 16916569, 21859206,22419565, 25186285, 26784347, 29218587, 29406610, 33741990]\n",
    "\n",
    "# testing:\n",
    "print(and_merge(sampl1,sample2))\n",
    "print(and_merge(inverted_index['group'],inverted_index['team']))\n",
    "print(and_merge([1,2,5,6,9], [2,4,5,7,8]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Similarly as above, implement the function `or_merge` outlined below that executes an OR merging of the lists. The resulting list should therefore include all the elements that appear in at least one of the lists. Again, this operation should take advantage of the input lists being sorted already, should not perform any additional sorting operation, and should go through each of the input lists just once. Elements that appear in both input list should only appear once in the output list. Test your function again with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_merge(sorted_list1, sorted_list2):\n",
    "    merged_list = []\n",
    "    # first we make copies of the lists, so we don't modify the existing lists in the index:\n",
    "    list1 = list(sorted_list1)\n",
    "    list2 = list(sorted_list2)\n",
    "\n",
    "    for id in list1: merged_list.append(id)\n",
    "\n",
    "    for id in list2:\n",
    "        if id in merged_list: continue\n",
    "        \n",
    "        merged_list.append(id)\n",
    "\n",
    "    return merged_list\n",
    "\n",
    "# testing:\n",
    "print(or_merge(sampl1,sample2))\n",
    "print(or_merge([1,2,5,6,9], [2,4,5,7,8]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Construct a function called `and_query` that takes as input a single string, consisting of one or more words, and returns as function value a list of matching documents. `and_query`, as its name suggests, should require that all query terms are present in the documents of the result list.\n",
    "\n",
    "For that, access the variable `inverted_index` from above and use the method `and_merge` that you defined. Also use the `tokenize` and `preprocess` functions we defined above to tokenize and preprocess your query.\n",
    "\n",
    "Again demonstrate the working of your function with an example (choose one that leads to fewer than 100 hits to not overblow this notebook file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34410788]\n",
      "Results for the AND-query 'sadness anger management':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1037//0012-1649.33.6.917>Social-contextual influences on expectancies for managing anger and sadness: the transition from middle childhood to adolescence.</a></strong><br>1997. Zeman J, Shipman K<br>[ID: 9383614]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1017/s0954579400001036>Emotion management skills in sexually maltreated and nonmaltreated girls: a developmental psychopathology perspective.</a></strong><br>2000. Shipman K, Zeman J, Penza S, Champion K<br>[ID: 10774595]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1207/S15374424JCCP3103_11>Anger and sadness regulation: predictions to internalizing and externalizing symptoms in children.</a></strong><br>2002. Zeman J, Shipman K, Suveg C<br>[ID: 12149977]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1111/j.2044-835X.2011.02050.x>Children's emotion regulation across and within nations: a comparison of Ghanaian, Kenyan, and American youth.</a></strong><br>2012. Morelen D, Zeman J, Perry-Parrish C, Anderson E<br>[ID: 22882371]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1007/s10964-020-01312-z>Conflict Resolution and Emotional Expression in Mother-Preadolescent Dyads: Longitudinal Associations with Children's Socioemotional Development.</a></strong><br>2020. Ferrar SJ, Stack DM, Dickson DJ, Serbin LA<br>[ID: 32935251]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def and_query(query, docs=None):\n",
    "\tif docs is None:\t#supporting function - defining docs default paramenter as list caused some weird behaviour where the variable was saved when you called the function again for some reason\n",
    "\t\tdocs = []\n",
    "\n",
    "\tif type(query) == str:\t\t#initial state where query is a string\n",
    "\t\tquery = preprocess(tokenize(query))\n",
    "\t\tdocs.extend(inverted_index[query[0]]) #fill docs with documnts that include only the first term to be able to compare with something later one in the recursion\n",
    "\n",
    "\tif len(query) <= 1:  #'bottom\" of recursion where there's only one term left\n",
    "\t\treturn and_merge(docs,inverted_index[query[0]])\n",
    "\telse:\n",
    "\t\tdocs = and_merge(docs, inverted_index[query[0]]) #find common docs between already found document and documets including the next term - for the firt 'iteraion' docs and the term are the same documents\n",
    "\n",
    "\t\treturn and_query(query[1:], docs) #run and_query again with all the query exluding the current first term\n",
    "\n",
    "\n",
    "print(and_query('automated quality control'))\n",
    "example_query = \"sadness anger management\"  \n",
    "example_result = and_query(example_query)  \n",
    "print(\"Results for the AND-query '\" + example_query + \"':\")  \n",
    "for paper in example_result:  \n",
    "    display_summary(paper)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Construct another function called `or_query` that works in the same way as `and_query` you just implemented, but returns as function value the documents that contain _at least one_ of the words in the query, using the `or_merge` function you defined.\n",
    "\n",
    "Demonstrate the working of this function also with an example (again, choose one that leads to fewer than 100 hits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_query(query, docs=None):\n",
    "\tif docs is None:\n",
    "\t\tdocs = []\n",
    "\n",
    "\tif type(query) == str:\t\t#initial state where query is a string\n",
    "\t\tquery = preprocess(tokenize(query))\n",
    "\t\tdocs.extend(inverted_index[query[0]]) #fill docs with documnts that include only the first term to be able to compare with something later one in the recursion\n",
    "\n",
    "\tif len(query) <= 1:  #'bottom\" of recursion where there's only one term left\n",
    "\t\treturn or_merge(docs,inverted_index[query[0]])\t\n",
    "\telse:\n",
    "\t\tdocs = or_merge(docs, inverted_index[query[0]]) #find common docs between already found document and documets including the next term - for the firt 'iteraion' docs and the term are the same documents\n",
    "\n",
    "\t\treturn or_query(query[1:], docs) #run and_query again with all the query exlusing the current first term\n",
    "\n",
    "or_query('athens amsterdam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Why does `and_query('emotional factor experiment')` not return our example paper 34648542, even though it mentions emotional factors and experiments in the abstract? (You do not have to implement anything to fix this yet!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** I think it has something to do with the current linguisting processing. Perhaps if we employed a lematizer it would work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "34648542 in and_query('emotional factors experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstracts[34648542]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to the assignment via Canvas as a modified version of this Notebook file (file with `.ipynb` extension) that includes your code and your answers.\n",
    "\n",
    "Before submitting, restart the kernel and re-run the complete code (**Kernel > Restart & Run All**), and then check whether your assignment code still works as expected.\n",
    "\n",
    "Don't forget to add your name, and remember that the assignments have to be done **individually**, and that code sharing or copying are **strictly forbidden** and will be punished."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
